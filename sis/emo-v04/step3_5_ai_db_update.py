import datetime
import torch
from pymongo import MongoClient
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch.nn.functional as F

# ==========================================
# 1. AI ëª¨ë¸ ë¡œë“œ (KcELECTRA Finetuned)
# ==========================================
# ê¸°ë³¸: monologg/kcelectra-base-finetuned-nsmc (í•´ë‹¹ repoê°€ private/gatedì¼ ìˆ˜ ìˆìŒ)
# ë¡œë“œì— ì‹¤íŒ¨í•˜ë©´ ê³µê°œ sentiment ëª¨ë¸ë¡œ í´ë°±í•©ë‹ˆë‹¤.
from dotenv import load_dotenv
import os
load_dotenv()

# ìš°ì„ ìˆœìœ„: HUGGINGFACE_TOKEN ë˜ëŠ” HF_TOKEN í™˜ê²½ë³€ìˆ˜
hf_token = os.getenv("HUGGINGFACE_TOKEN") or os.getenv("HF_TOKEN")

# ëª¨ë¸ ì ‘ê·¼ ì‚¬ì „ ì²´í¬: Hugging Face APIë¡œ repo info í™•ì¸
from huggingface_hub import HfApi

def check_repo_access(repo_id, token=None):
    api = HfApi()
    try:
        api.model_info(repo_id, token=token)
        return True
    except Exception as e:
        print(f"âš ï¸ ëª¨ë¸ ì ‘ê·¼ ì²´í¬ ì‹¤íŒ¨: {e}")
        return False

v_model_name = "monologg/koelectra-base-finetuned-nsmc"
try:
    if hf_token:
        print("ğŸ” Hugging Face token detected in environment; checking repo access...")
        if not check_repo_access(v_model_name, token=hf_token):
            raise Exception(f"ëª¨ë¸ {v_model_name} ì ‘ê·¼ ë¶ˆê°€(í† í° ê¶Œí•œ ë¶€ì¡± ë˜ëŠ” repo ì—†ìŒ).")
        # use `token=` (newer API) and fallback to `use_auth_token=` for compatibility
        try:
            v_tokenizer = AutoTokenizer.from_pretrained(v_model_name, token=hf_token)
            v_model = AutoModelForSequenceClassification.from_pretrained(v_model_name, token=hf_token)
        except TypeError:
            v_tokenizer = AutoTokenizer.from_pretrained(v_model_name, use_auth_token=hf_token)
            v_model = AutoModelForSequenceClassification.from_pretrained(v_model_name, use_auth_token=hf_token)
    else:
        v_tokenizer = AutoTokenizer.from_pretrained(v_model_name)
        v_model = AutoModelForSequenceClassification.from_pretrained(v_model_name)
    v_is_fallback_multiclass = False
except Exception as e:
    import sys
    print(f"âš ï¸ ëª¨ë¸ ë¡œë“œ ì˜¤ë¥˜: {e}")
    print("í•´ê²°ì±…: 1) ì´ ëª¨ë¸ì´ private/gatedì´ë©´ Hugging Face í† í°ì„ ë°œê¸‰í•´ì„œ .envì— `HUGGINGFACE_TOKEN=hf_xxx`ë¡œ ì„¤ì •í•˜ê±°ë‚˜, CLIë¡œ ë¡œê·¸ì¸í•˜ì„¸ìš”.")
    print("         2) CLI ë¡œê·¸ì¸: `huggingface-cli login` (ê¶Œí•œ ìˆëŠ” í† í°ìœ¼ë¡œ ë¡œê·¸ì¸)")
    print("         3) ë˜ëŠ” ê³µê°œ ëª¨ë¸ë¡œ í´ë°±í•©ë‹ˆë‹¤: nlptown/bert-base-multilingual-uncased-sentiment")

    # ê³µê°œ í´ë°± ëª¨ë¸ (ë‹¤ì¤‘ í´ë˜ìŠ¤: 1~5ì )
    v_model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
    try:
        if hf_token:
            try:
                v_tokenizer = AutoTokenizer.from_pretrained(v_model_name, token=hf_token)
                v_model = AutoModelForSequenceClassification.from_pretrained(v_model_name, token=hf_token)
            except TypeError:
                v_tokenizer = AutoTokenizer.from_pretrained(v_model_name, use_auth_token=hf_token)
                v_model = AutoModelForSequenceClassification.from_pretrained(v_model_name, use_auth_token=hf_token)
        else:
            v_tokenizer = AutoTokenizer.from_pretrained(v_model_name)
            v_model = AutoModelForSequenceClassification.from_pretrained(v_model_name)
        v_is_fallback_multiclass = True
        print(f"í´ë°± ëª¨ë¸ ë¡œë“œ ì„±ê³µ: {v_model_name}")
    except Exception as e2:
        print("âš ï¸ í´ë°± ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤:", e2)
        print("ê°€ëŠ¥í•œ ì›ì¸: PyTorch/torchvisionì˜ ë²„ì „ ë¶ˆì¼ì¹˜ ë˜ëŠ” ì„¤ì¹˜ ë¬¸ì œ.")
        print("í•´ê²°: ì•„ë˜ ëª…ë ¹ì–´ë¡œ PyTorchì™€ torchvisionì„ í˜¸í™˜ ë²„ì „ìœ¼ë¡œ ì¬ì„¤ì¹˜í•˜ì„¸ìš” (ì˜ˆì‹œ):")
        print("  pip uninstall torchvision && pip install --upgrade --force-reinstall torch torchvision")
        print("ë˜ëŠ” í™˜ê²½ ì •ë³´(íŒŒì´ì¬, torch, torchvision ë²„ì „)ë¥¼ ì œê³µí•´ ì£¼ì„¸ìš”.")
        sys.exit(1)

print(f"Loaded model: {v_model_name}")

# ==========================================
# 2. ê°ì„± ë¶„ì„ ì—”ì§„ í•¨ìˆ˜ (AI ë‡Œ)
# ==========================================

def get_ai_sentiment_score(in_text):
    # í…ìŠ¤íŠ¸ë¥¼ AIê°€ ì´í•´í•  ìˆ˜ ìˆëŠ” ìˆ«ìë¡œ ë³€í™˜
    v_inputs = v_tokenizer(in_text, return_tensors="pt", truncation=True, max_length=128)
    
    with torch.no_grad():
        v_outputs = v_model(**v_inputs)
    
    # í™•ë¥ ê°’ ê³„ì‚° (Softmax)
    v_probs = F.softmax(v_outputs.logits, dim=-1)[0].cpu().numpy()

    # ì´ì§„ ë¶„ë¥˜(neg,pos) ëª¨ë¸ì´ë©´ index 1ì´ ê¸ì • í™•ë¥ 
    if (not v_is_fallback_multiclass) and (v_probs.shape[0] == 2):
        v_pos_prob = float(v_probs[1])
        # 0~1 -> -1~1
        v_final_score = round((v_pos_prob * 2) - 1, 3)
    else:
        # ë‹¤ì¤‘ í´ë˜ìŠ¤(ì˜ˆ: 1~N rating) ëª¨ë¸: ê¸°ëŒ€ í‰ì (expected_rating)ì„ ê³„ì‚°í•´ -1..1ë¡œ ë§¤í•‘
        classes = v_probs.shape[0]
        expected_rating = sum((i + 1) * float(p) for i, p in enumerate(v_probs))  # 1..N
        mid = (classes + 1) / 2.0
        denom = (classes - 1) / 2.0
        v_final_score = round((expected_rating - mid) / denom, 3)

    return v_final_score

# ==========================================
# 3. DB ì—…ë°ì´íŠ¸ ë©”ì¸ ë¡œì§
# ==========================================
def run_ai_db_enrichment():
    v_client = MongoClient(os.getenv("MONGO_DB_URL"))
    v_db = v_client['mock_trading_db']
    v_col = v_db['emo_db']
    
    # 1,127ê±´ ì „ì²´ ë˜ëŠ” ì ìˆ˜ê°€ 0ì´ì—ˆë˜ ë°ì´í„° ëŒ€ìƒ [cite: 2025-12-31]
    v_cursor = v_col.find({"status": "sentiment_completed"})
    
    v_total = v_col.count_documents({"status": "sentiment_completed"})
    v_count = 0

    print(f"ğŸš€ AI ëª¨ë¸ ê°€ë™: ì´ {v_total}ê±´ì˜ ë°ì´í„° ê³ ë„í™” ì‹œì‘...")

    for v_doc in v_cursor:
        v_id = v_doc["_id"]
        v_term = v_doc["term"]
        
        # AI ì ìˆ˜ ê³„ì‚° [cite: 2025-12-31]
        v_ai_score = get_ai_sentiment_score(v_term)
        
        # [ì—…ë°ì´íŠ¸] AI ì ìˆ˜ ë°˜ì˜ ë° ìƒíƒœ ì—…ë°ì´íŠ¸
        v_col.update_one(
            {"_id": v_id},
            {
                "$set": {
                    "analysis.sentiment_score": v_ai_score,
                    "status": "ai_analyzed", # AI ë¶„ì„ ì™„ë£Œ ìƒíƒœ
                    "ai_updated_at": datetime.datetime.now()
                }
            }
        )
        
        v_count += 1
        if v_count % 10 == 0:
            print(f"ğŸ“‘ [{v_count}/{v_total}] '{v_term}' ë¶„ì„ ì™„ë£Œ -> ì ìˆ˜: {v_ai_score}")

    return v_count

if __name__ == "__main__":
    print("ğŸ§  [ê²Œìœ¼ë¥¸ ë‹¬ê±€] Phase 3.5: AI ì§€ëŠ¥ ì£¼ì… í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰")
    print("-" * 60)
    
    v_processed = run_ai_db_enrichment()
    
    print("-" * 60)
    print(f"âœ… ì´ {v_processed}ê±´ì˜ ë°ì´í„°ê°€ AI ì ìˆ˜ë¡œ ì •ë°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤.") 
    print("ğŸ ì´ì œ 'íŒŒë„ íŒŒë„ ê´´ë‹´'ì„ ê²€ìƒ‰í•´ì„œ ì ìˆ˜ê°€ ì–´ë–»ê²Œ ë³€í–ˆëŠ”ì§€ í™•ì¸í•´ ë³´ì„¸ìš”!")