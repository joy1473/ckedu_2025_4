import os
from datetime import datetime
from dotenv import load_dotenv
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pymongo import MongoClient
import uvicorn
import torch
import torch.nn.functional as F
from transformers import AutoTokenizer, AutoModelForSequenceClassification
from openai import OpenAI

# 1. ì´ˆê¸°í™” ë° ë³´ì•ˆ ì„¤ì •
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
client_gpt = OpenAI(api_key=OPENAI_API_KEY)

app = FastAPI(title="Antygravity K-Stock AI Agent v2.8", version="2.8.0")
app.add_middleware(CORSMiddleware, allow_origins=["*"], allow_methods=["*"], allow_headers=["*"])

# ---------------------------------------------------------
# ğŸ› ï¸ [ì›¹ë§ˆìŠ¤í„° ì „ìš©] K-ì£¼ì‹ ë„ë©”ì¸ ê°€ë“œë ˆì¼ (ì ˆëŒ€ ê·œì¹™)
# ---------------------------------------------------------
AI_AGENT_CONFIG = {
    "PERSONA": """
        ë„ˆëŠ” í•œêµ­ ì£¼ì‹ ì‹œì¥ì— íŠ¹í™”ëœ â€˜ì „ë¬¸ ê¸ˆìœµ í†µì—­ AI Agentâ€™ì•¼.
        ê¸€ë¡œë²Œ í‘œì¤€(ë¹¨ê°„ìƒ‰=í•˜ë½)ì„ ì™„ì „íˆ ìŠê³ , ì˜¤ì§ í•œêµ­ ì‹œì¥ì˜ ê·œì¹™ì„ ë”°ë¥¸ë‹¤.
        
        [K-ì£¼ì‹ ì ˆëŒ€ ì›ì¹™]
        1. ìƒ‰ìƒ ë¬¸ë§¥: ë¹¨ê°„ìƒ‰/ë¹¨ê°„ ë¶ˆ/ë¶ˆê¸°ë‘¥ = ë¬´ì¡°ê±´ 'ìì‚° ê°€ì¹˜ ìƒìŠ¹' ë° 'ìˆ˜ìµ'. (ê¸ì • ì‹œë‚˜ë¦¬ì˜¤)
        2. ìƒ‰ìƒ ë¬¸ë§¥: íŒŒë€ìƒ‰/íŒŒë€ ë¶ˆ/ë¬¼ë ¸ë‹¤ = ë¬´ì¡°ê±´ 'ìì‚° ê°€ì¹˜ í•˜ë½' ë° 'ì†ì‹¤'. (ë¶€ì • ì‹œë‚˜ë¦¬ì˜¤)
        
        [ê¸ˆìœµ í†µì—­ ì‚¬ì „ - í•„ìˆ˜ ì¹˜í™˜]
        - 'ë¹¨ê°„ ë¶ˆ/ë¶ˆê¸°ë‘¥' -> 'ì£¼ê°€ ìƒìŠ¹ì— ë”°ë¥¸ ë§¤ìˆ˜ì„¸ ê°•í™”'
        - 'íŒŒë€ ë¶ˆ/íŒŒë‘ìƒˆ' -> 'ì£¼ê°€ í•˜ë½ì— ë”°ë¥¸ ë§¤ë„ì„¸ ìš°ìœ„'
        - 'ì»¤í”¼ê°’/ì¹˜í‚¨ê°’' -> 'ì‹¤í˜„ ê°€ëŠ¥í•œ ì†Œì•¡ íˆ¬ì ìˆ˜ìµ'
        - 'ì¡´ë²„' -> 'ì¥ê¸° ë³´ìœ ë¥¼ í†µí•œ ì¸ë‚´ íˆ¬ì'
        - 'í’€ë§¤ìˆ˜/ëª°ë¹µ' -> 'ìì‚°ì˜ ì§‘ì¤‘ ë§¤ì…'
        
        [ë‹µë³€ ê°€ì´ë“œ]
        - INTERPRETATION: ì‚¬ìš©ìì˜ ê°ì •ê³¼ ì€ì–´ë¥¼ ìœ„ ì‚¬ì „ì— ë”°ë¼ ê¸ˆìœµ í‘œì¤€ì–´ë¡œ 'í†µì—­'í•´.
        - ANSWER: ì‹¤ì œ í†µì—­ì‚¬ì²˜ëŸ¼ ì •ì¤‘í•œ ê²©ì‹ì²´(...ë“œë¦½ë‹ˆë‹¤, ...ê¶Œê³ í•©ë‹ˆë‹¤)ë¥¼ ì‚¬ìš©í•´.
        - ë°˜ë“œì‹œ ë¶ˆì™„ì „ íŒë§¤ ë°©ì§€ë¥¼ ìœ„í•´ ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë©˜íŠ¸ë¥¼ í¬í•¨í•´.
    """
}

# AI ëª¨ë¸ ë¡œë”© (koelectra)
v_model_name = "monologg/koelectra-base-finetuned-nsmc"
v_tokenizer = AutoTokenizer.from_pretrained(v_model_name)
v_model = AutoModelForSequenceClassification.from_pretrained(v_model_name)

# DB ì—°ê²°
client_db = MongoClient("mongodb://localhost:27017/")
db = client_db["game_db"]
log_collection = db["test_logs"]

# ==========================================
# 2. ì§€ëŠ¥í˜• í†µì—­ ë° ì‹œë‚˜ë¦¬ì˜¤ êµì • í•¨ìˆ˜
# ==========================================

def get_ai_agent_mentoring(term: str, score: float):
    """
    GPTê°€ ì›ë¬¸ì˜ 'Intent'ë¥¼ ë¶„ì„í•˜ì—¬ ëª¨ë¸ì˜ ì˜¤íŒì„ êµì •í•˜ê³  
    ì „ë¬¸ì ì¸ ê¸ˆìœµ í†µì—­ ê²°ê³¼ë¥¼ ìƒì„±í•¨. [cite: 2026-01-04]
    """
    v_system_content = f"""
    {AI_AGENT_CONFIG["PERSONA"]}
    
    [ì‹¤ì‹œê°„ ë¶„ì„ ì§€ì¹¨]
    - ì…ë ¥: "{term}" (AI ì ìˆ˜: {score})
    - ë§Œì•½ ì…ë ¥ì— 'ë¹¨ê°„' í˜¹ì€ ìƒìŠ¹ ì˜ë¯¸ê°€ ìˆë‹¤ë©´ AI ì ìˆ˜ê°€ ë‚®ì•„ë„ ë¬´ì¡°ê±´ POSITIVE íƒœê·¸ë¥¼ ë¶€ì—¬í•´.
    
    ì¶œë ¥ í˜•ì‹:
    TAG: (EXTREME_NEGATIVE / MODERATE_NEGATIVE / NEUTRAL / MODERATE_POSITIVE / EXTREME_POSITIVE)
    INTERPRETATION: (ê°ì • ìƒíƒœì˜ ê¸ˆìœµì  í†µì—­)
    ANSWER: (ê²©ì¡° ìˆëŠ” ì „ë¬¸ ì¡°ì–¸)
    """
    
    try:
        response = client_gpt.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "system", "content": v_system_content}],
            temperature=0.0 # ì¼ê´€ì„±ì„ ìœ„í•´ ë¬´ì‘ìœ„ì„± ì œê±°
        )
        res_text = response.choices[0].message.content
        
        v_tag, v_interp, v_ans = "NEUTRAL", "ë¶„ì„ ì¤‘...", "ì¡°ì–¸ ì¤€ë¹„ ì¤‘..."
        for line in res_text.split('\n'):
            if line.startswith("TAG:"): v_tag = line.replace("TAG:", "").strip()
            if line.startswith("INTERPRETATION:"): v_interp = line.replace("INTERPRETATION:", "").strip()
            if line.startswith("ANSWER:"): v_ans = line.replace("ANSWER:", "").strip()
            
        return v_tag, v_interp, v_ans
    except Exception as e:
        return "ERROR", str(e), "ì‹œìŠ¤í…œ ì¼ì‹œ ì˜¤ë¥˜"

# ==========================================
# 3. í†µí•© API ì—”ë“œí¬ì¸íŠ¸
# ==========================================

@app.get("/agent/consult", tags=["AI Agent"])
def financial_consultation(term: str):
    # [1] ê¸°ì´ˆ ê°ì„± ë¶„ì„
    v_inputs = v_tokenizer(term, return_tensors="pt", truncation=True, max_length=128)
    with torch.no_grad():
        v_outputs = v_model(**v_inputs)
    v_score = round((F.softmax(v_outputs.logits, dim=-1)[0][1].item() * 2) - 1, 3)
    
    # [2] GPT ê¸°ë°˜ ì§€ëŠ¥í˜• êµì • ë° í†µì—­
    v_tag, v_interp, v_mentoring = get_ai_agent_mentoring(term, v_score)
    
    # [3] ë¡œê¹… (íŒ€ì›ë“¤ê³¼ ê³µìœ í•  í•µì‹¬ ë°ì´í„°)
    log_collection.insert_one({
        "timestamp": datetime.now(),
        "user_input": term,
        "raw_score": v_score,
        "final_tag": v_tag,
        "interpretation": v_interp,
        "ai_response": v_mentoring,
        "version": "2.8.0-final-guardrail"
    })
    
    return {
        "status": "success",
        "analysis": {"term": term, "score": v_score, "tag": v_tag},
        "emotion_interpretation": v_interp,
        "professional_response": v_mentoring
    }

if __name__ == "__main__":
    uvicorn.run("main:app", host="127.0.0.1", port=8000, reload=True)